{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports were added on from old HW's we've had\n",
    "* some aren't used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Standard python helper libraries.\n",
    "import os, sys, re, json, time\n",
    "import itertools\n",
    "import collections\n",
    "from IPython.display import display\n",
    "\n",
    "# NumPy and SciPy for matrix ops\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "# Pandas because pandas are awesome\n",
    "import pandas as pd\n",
    "# Set pandas floating point display\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# NLTK for NLP utils\n",
    "import nltk\n",
    "\n",
    "# Helper libraries\n",
    "import utils\n",
    "#import vocabulary\n",
    "\n",
    "# Plotly imports.\n",
    "import plotly.offline as plotly\n",
    "plotly.offline.init_notebook_mode()\n",
    "import plotly.graph_objs as go\n",
    "from pprint import pprint\n",
    "import sqlalchemy\n",
    "import sqlite3\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function I found just to list out table names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importdb(db):\n",
    "    \n",
    "    conn = sqlite3.connect(db)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in c.fetchall():\n",
    "        print (table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('reviews',)\n",
      "('products',)\n",
      "('categories',)\n"
     ]
    }
   ],
   "source": [
    "importdb(\"reviews.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create pandas DF for reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>??</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>ASIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL17959WYMDQO</td>\n",
       "      <td>5</td>\n",
       "      <td>for sizing</td>\n",
       "      <td>2015-07-23</td>\n",
       "      <td>I wear a size 8 in women's so I ordered a size...</td>\n",
       "      <td>B06XRW26VW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RPDE4MBK5YZ02</td>\n",
       "      <td>4</td>\n",
       "      <td>Seem to run a little narrow</td>\n",
       "      <td>2017-11-19</td>\n",
       "      <td>Own several pair of these, this pair seems to ...</td>\n",
       "      <td>B06XRW26VW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1T62C0ORV3J9E</td>\n",
       "      <td>5</td>\n",
       "      <td>My daughter is in love with these</td>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>My daughter is in love with these. the first p...</td>\n",
       "      <td>B06XRW26VW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1OA8AZV9I45U8</td>\n",
       "      <td>5</td>\n",
       "      <td>Just love these shoes</td>\n",
       "      <td>2017-09-18</td>\n",
       "      <td>Just love these shoes! And cheaper than anywhe...</td>\n",
       "      <td>B06XRW26VW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R21370ICYS03G6</td>\n",
       "      <td>5</td>\n",
       "      <td>but like always, Amazon came through</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Met my expectations perfectly! They were sold ...</td>\n",
       "      <td>B06XRW26VW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ??  rating                                 title       date  \\\n",
       "0   RL17959WYMDQO       5                            for sizing 2015-07-23   \n",
       "1   RPDE4MBK5YZ02       4           Seem to run a little narrow 2017-11-19   \n",
       "2  R1T62C0ORV3J9E       5     My daughter is in love with these 2017-01-12   \n",
       "3  R1OA8AZV9I45U8       5                 Just love these shoes 2017-09-18   \n",
       "4  R21370ICYS03G6       5  but like always, Amazon came through 2016-09-07   \n",
       "\n",
       "                                              review        ASIN  \n",
       "0  I wear a size 8 in women's so I ordered a size...  B06XRW26VW  \n",
       "1  Own several pair of these, this pair seems to ...  B06XRW26VW  \n",
       "2  My daughter is in love with these. the first p...  B06XRW26VW  \n",
       "3  Just love these shoes! And cheaper than anywhe...  B06XRW26VW  \n",
       "4  Met my expectations perfectly! They were sold ...  B06XRW26VW  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"reviews.db\")\n",
    "c = conn.cursor()\n",
    "c.execute(\"Select * from reviews;\")\n",
    "review_table = pd.DataFrame(c.fetchall())\n",
    "# Didn't know what the first column was\n",
    "\n",
    "review_table.columns = [\"??\",\"rating\",\"title\",\"date\",\"review\",\"ASIN\"]\n",
    "\n",
    "# review_table.head()\n",
    "review_table[\"rating\"] = review_table.rating.apply(lambda x: int(x))\n",
    "review_table[\"date\"] = review_table.date.apply(lambda x: datetime.datetime.strptime(x, \"%B %d, %Y\"))\n",
    "review_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62994, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    43587\n",
       "4    10357\n",
       "3     4052\n",
       "1     2831\n",
       "2     2167\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_table.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(review_table.ASIN[review_table.rating<4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc_complete is what I use as the corpus that will be trained on\n",
    "* below this is all reviews that have ratings less than 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_complete = [i for i in review_table.review[review_table.rating<4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6810"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below I'm playing around with the idea of removing all words that only appear once as it probably wouldn't contribute to topic selection anyway. \n",
    "\n",
    "* May be a good idea to play around with tf_idf...I need to go through a refresher to gain familiarity with the subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = []\n",
    "\n",
    "for doc in doc_complete:\n",
    "    all_words.extend([x.lower() for x in doc.split(' ')])\n",
    "from collections import Counter\n",
    "counts = Counter(all_words)   \n",
    "\n",
    "wc = pd.DataFrame.from_dict(counts,orient=\"index\")\n",
    "\n",
    "one_time = set(wc.index[wc[0]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 10637),\n",
       " ('i', 7288),\n",
       " ('a', 5728),\n",
       " ('and', 5555),\n",
       " ('to', 4409),\n",
       " ('they', 3242),\n",
       " ('of', 3040),\n",
       " ('but', 2895),\n",
       " ('is', 2798),\n",
       " ('for', 2761),\n",
       " ('my', 2628),\n",
       " ('are', 2421),\n",
       " ('not', 2403),\n",
       " ('these', 2365),\n",
       " ('in', 2355),\n",
       " ('it', 2277),\n",
       " ('size', 1808),\n",
       " ('them', 1779),\n",
       " ('was', 1778),\n",
       " ('on', 1747),\n",
       " ('too', 1707),\n",
       " ('have', 1584),\n",
       " ('that', 1521),\n",
       " ('this', 1404),\n",
       " ('shoes', 1345),\n",
       " ('like', 1264),\n",
       " ('very', 1256),\n",
       " ('so', 1174),\n",
       " ('as', 1159),\n",
       " ('with', 1140),\n",
       " ('were', 1058),\n",
       " ('fit', 1044),\n",
       " ('be', 986),\n",
       " ('shoe', 958),\n",
       " ('had', 872),\n",
       " ('you', 866),\n",
       " ('just', 816),\n",
       " ('if', 805),\n",
       " ('adidas', 803),\n",
       " ('at', 767),\n",
       " ('would', 763),\n",
       " ('wear', 737),\n",
       " ('than', 720),\n",
       " ('after', 621),\n",
       " ('small', 613),\n",
       " ('one', 603),\n",
       " ('because', 596),\n",
       " ('ordered', 592),\n",
       " ('pair', 579),\n",
       " ('good', 579),\n",
       " ('or', 568),\n",
       " ('bought', 566),\n",
       " ('up', 549),\n",
       " ('when', 529),\n",
       " (\"i'm\", 528),\n",
       " ('way', 521),\n",
       " ('look', 519),\n",
       " ('will', 516),\n",
       " ('from', 515),\n",
       " (\"don't\", 509),\n",
       " ('little', 509),\n",
       " ('pants', 504),\n",
       " ('an', 485),\n",
       " ('really', 472),\n",
       " ('more', 469),\n",
       " ('big', 463),\n",
       " ('get', 460),\n",
       " (\"it's\", 453),\n",
       " ('them.', 438),\n",
       " ('me', 437),\n",
       " ('quality', 428),\n",
       " ('other', 426),\n",
       " ('only', 422),\n",
       " ('great', 420),\n",
       " ('all', 420),\n",
       " ('no', 418),\n",
       " ('return', 416),\n",
       " ('out', 407),\n",
       " ('what', 400),\n",
       " ('feet', 399),\n",
       " ('he', 397),\n",
       " ('even', 393),\n",
       " ('got', 386),\n",
       " ('son', 385),\n",
       " ('has', 375),\n",
       " ('about', 374),\n",
       " ('am', 364),\n",
       " ('your', 350),\n",
       " ('large', 344),\n",
       " ('do', 338),\n",
       " ('still', 335),\n",
       " ('we', 333),\n",
       " ('comfortable', 328),\n",
       " ('nice', 326),\n",
       " ('material', 317),\n",
       " ('buy', 316),\n",
       " ('run', 310),\n",
       " ('bit', 306),\n",
       " ('off', 305),\n",
       " ('wearing', 302)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc clean below is the corpus cleansed of stop words, some punctuation and word stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop = set(stopwords.words('english'))\n",
    "#Extra stop words below\n",
    "stop.update({'adidas','shoe','shoes','pant','pants'})\n",
    "stop.update(one_time)\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in doc_complete] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "#row is document, first value is word, second is wordcount\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just looking at format of dictionary...can ignore\n",
    "for i in dictionary:\n",
    "    if i < 10:\n",
    "        print (i,dictionary[i])\n",
    "    else:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTUAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=6, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around with what the package has to offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foot', 0.027876126599764722),\n",
       " ('like', 0.014290692661209614),\n",
       " ('shoe', 0.014107389679758444),\n",
       " ('wear', 0.013363535699399251),\n",
       " ('would', 0.011863486618215579),\n",
       " ('really', 0.011563455880973936),\n",
       " ('comfortable', 0.011382413378347556),\n",
       " ('look', 0.010595276455863162),\n",
       " ('narrow', 0.010534889104093862),\n",
       " ('them', 0.0099304368665102411)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.show_topic(topicid=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.027*\"fit\" + 0.021*\"bag\"'),\n",
       " (1, '0.021*\"pair\" + 0.017*\"year\"'),\n",
       " (2, '0.035*\"color\" + 0.019*\"like\"'),\n",
       " (3, '0.028*\"foot\" + 0.014*\"like\"'),\n",
       " (4, '0.023*\"foot\" + 0.022*\"sandal\"'),\n",
       " (5, '0.095*\"size\" + 0.032*\"small\"')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_topics=6, num_words=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ignore Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter = pd.read_csv(\"twitter.csv\",header=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews[pd.isnull(reviews.Text)==False].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datetime.datetime.strptime(\"03-JAN-17\", '%d-%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_date(x):\n",
    "    if pd.isnull(x) == False:\n",
    "        return datetime.datetime.strptime(x, '%d-%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews[\"date\"] = reviews[\"Submission Day\"].apply(to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews[\"rating\"] = reviews['Monthly Star Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews[['date','Product','Category','rating','Text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Later take a look at similarities by specific star rating\n",
    "* Decided to look at full corpus for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_star_text = ''\n",
    "\n",
    "for text in reviews.Text[reviews.rating == 1]:\n",
    "    one_star_text += '<s>' + re.sub(r'[^\\w\\s]',' ',re.sub(\"'\",'',text.lower()))\n",
    "    how_many += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.sub(' +',' ','The     quick brown    fox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_text = ''\n",
    "\n",
    "for text in twitter.Content:\n",
    "    twitter_text += ' <s> ' + re.sub(r'[^\\w\\s]',' ',re.sub(\"'\",'',str(text).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_text = re.sub(' +',' ',twitter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon_text = ''\n",
    "amazon_text_list = []\n",
    "\n",
    "#how_many =0\n",
    "\n",
    "for text in reviews.Text:\n",
    "    amazon_text += ' <s> ' + re.sub(r'[^\\w\\s]',' ',re.sub(\"'\",'',str(text).lower()))+ ' <\\s> '\n",
    "    #how_many+=1\n",
    "    \n",
    "for text in reviews.Text:\n",
    "    amazon_text_list.append(' <s> ' + re.sub(r'[^\\w\\s]',' ',re.sub(\"'\",'',str(text).lower()))+ ' <\\s> ')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon_text = re.sub(' +',' ',all_text)\n",
    "amazon_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon_words = amazon_text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = defaultdict(int)\n",
    "\n",
    "\n",
    "\n",
    "for word in amazon_words:\n",
    "    word_count[word]+=1\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wc_df =pd.DataFrame.from_dict(word_count,orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wc_df['word'] = wc_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wc_df.reset_index(inplace=True)\n",
    "wc_df.columns = [\"word\",\"count\"]\n",
    "wc_df['index_1'] = wc_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wc_df.sort_values(by=[\"count\",\"word\"],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wc_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_id = {}\n",
    "\n",
    "for i,row in wc_df.iterrows():\n",
    "    word_id[row.word]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_id['to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cooccurrence_matrix(token_ids, V, K=2):\n",
    "    # We'll use this as an \"accumulator\" matrix\n",
    "    C = scipy.sparse.csc_matrix((V,V), dtype=np.float32)\n",
    "\n",
    "    for k in range(1, K+1):\n",
    "        print (u\"Counting pairs (i, i \\u00B1 %d) ...\" % k)\n",
    "        i = token_ids[:-k]  # current word\n",
    "        j = token_ids[k:]   # k words ahead\n",
    "        data = (np.ones_like(i), (i,j))  # values, indices\n",
    "        Ck_plus = scipy.sparse.coo_matrix(data, shape=C.shape, dtype=np.float32)\n",
    "        Ck_plus = scipy.sparse.csc_matrix(Ck_plus)\n",
    "        Ck_minus = Ck_plus.T  # Consider k words behind\n",
    "        C += Ck_plus + Ck_minus\n",
    "\n",
    "    print (\"Co-occurrence matrix: %d words x %d words\" % (C.shape))\n",
    "    print (\"  %.02g nonzero elements\" % (C.nnz))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show co-occurrence on a toy corpus\n",
    "\n",
    "\n",
    "amazon_text_list\n",
    "\n",
    "#words\n",
    "\n",
    "\n",
    "amazon_words\n",
    "\n",
    "# ?\n",
    "\n",
    "# sentence_to_ids adds \"<s>\" and \"</s>\"\n",
    "\n",
    "#gives id of words\n",
    "\n",
    "\n",
    "\n",
    "amazon_words_ids = [word_id[s] for s in amazon_words]\n",
    "\n",
    "# Here's the important part\n",
    "\n",
    "\n",
    "amazon_C = cooccurrence_matrix(amazon_words_ids, len(amazon_words), K = 1)\n",
    "\n",
    "#ORdered from most common to least common than reverse alphabetical\n",
    "\n",
    "#pretty_print_matrix(amazon_C.toarray(), rows=wc_df.word, \n",
    "#                          cols=wc_df.word, dtype=int, highlight=\"> 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PPMI(C):\n",
    "    \"\"\"Tranform a counts matrix to PPMI.\n",
    "    \n",
    "    Args:\n",
    "      C: scipy.sparse.csc_matrix of counts C_ij\n",
    "    \n",
    "    Returns:\n",
    "      (scipy.sparse.csc_matrix) PPMI(C) as defined above\n",
    "    \"\"\"\n",
    "    Z = float(C.sum())  # total counts\n",
    "    # sum each column (along rows)\n",
    "    Zc = np.array(C.sum(axis=0), dtype=np.float64).flatten()\n",
    "    # sum each row (along columns)\n",
    "    Zr = np.array(C.sum(axis=1), dtype=np.float64).flatten()\n",
    "    \n",
    "    # Get indices of relevant elements\n",
    "    ii, jj = C.nonzero()  # row, column indices\n",
    "    Cij = np.array(C[ii,jj], dtype=np.float64).flatten()\n",
    "    \n",
    "    ##\n",
    "    # PMI equation\n",
    "    pmi = np.log(Cij * Z / (Zr[ii] * Zc[jj]))\n",
    "    ##\n",
    "    # Truncate to positive only\n",
    "    ppmi = np.maximum(0, pmi)  # take positive only\n",
    "    \n",
    "    # Re-format as sparse matrix\n",
    "    ret = scipy.sparse.csc_matrix((ppmi, (ii,jj)), shape=C.shape,\n",
    "                                  dtype=np.float64)\n",
    "    ret.eliminate_zeros()  # remove zeros\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "def SVD(X, d=100):\n",
    "    \"\"\"Returns word vectors from SVD.\n",
    "    \n",
    "    Args:\n",
    "      X: m x n matrix\n",
    "      d: word vector dimension\n",
    "      \n",
    "    Returns:\n",
    "      Wv : m x d matrix, each row is a word vector.\n",
    "    \"\"\"\n",
    "    transformer = TruncatedSVD(n_components=d, random_state=1)\n",
    "    Wv = transformer.fit_transform(X)\n",
    "    # Normalize to unit length\n",
    "    Wv = Wv / np.linalg.norm(Wv, axis=1).reshape([-1,1])\n",
    "    return Wv, transformer.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 1\n",
    "d = 100\n",
    "t0 = time.time()\n",
    "C = cooccurrence_matrix(amazon_words_ids, len(amazon_words), K=K)\n",
    "\n",
    "C_ppmi = PPMI(C)\n",
    "\n",
    "Wv, _ = SVD(C_ppmi, d=d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "data = [go.Scatter(x=Wv[:n,0], y=Wv[:n,1], text=amazon_words[:n],\n",
    "                   mode='markers', textposition='bottom', hoverinfo='text')]\n",
    "fig = go.Figure(data=data, layout=go.Layout(title=\"Word Embeddings\", hovermode='closest'))\n",
    "plotly.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
